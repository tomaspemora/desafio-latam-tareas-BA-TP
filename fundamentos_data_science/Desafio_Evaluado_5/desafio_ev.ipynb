{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as lr\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('boston.csv', index_col = 0)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dividir la muestra (1 puntos)\n",
    "* Genere conjuntos de entrenamiento y pruebas con train_test_split .\n",
    "* Reserve un 33% de la muestra para el conjunto de pruebas.\n",
    "* Incluya una semilla pseudoaleatoria a su elección, esto lo puede hacer con el\n",
    "argumento random_state dentro del método train_test_plit.\n",
    "\n",
    "---\n",
    "Comentarios: Ultima clase de Alfonso para Holdout del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generar modelos (2 puntos)\n",
    "* Ahora implementaremos dos versiones del modelo lineal:\n",
    "    - Con intercepto.\n",
    "    - Sin intercepto.\n",
    "* Cada versión debe generarse en un nuevo objeto inicializado.\n",
    "* Posteriormente se deben entrenar los modelos especificando la matriz y vector de entrenamiento.\n",
    "* Con los modelos entrenados, genere una predicción de la matriz de pruebas con el método .predict().\n",
    "---\n",
    "pto 1 y 2: \n",
    "* Primero seleccionar columnas descriptores (df.columns) y la variable a describir (df.drop (medv))\n",
    "* X = sm.add_constant(x) (con intercepto) y sin intercepto X = x\n",
    "* Identifico el plano de regresión lineal con OLS (Ordinary Least Squares) usaremos el modulo statsmodels con las funciones model = sm.OLS.\n",
    "* Fitear el modelo con model.fit()\n",
    "* Evaluar usando model.summary()\n",
    "\n",
    "pto 3:\n",
    "* Handout usando X_train, X_test, y_train, y_test = train_test_split\n",
    "* Estudiar la data. puede servir sns.pairplot, df.describe y ver que pasos del pipeline necesitamos (escalar, normalizar, redefinir variables categoricas OneHotEncoder, etc)\n",
    "* Crear el pipeline con Pipeline(steps=[('scaler', StandardScaler()), ('model', LinearRegression())])\n",
    "* Fitear el pipeline con pipeline.fit()\n",
    "\n",
    "pto 4:\n",
    "* Predecir con pipeline.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Obtención de métricas (1 puntos)\n",
    "* Ahora generaremos una función llamada report_scores que ingrese como argumentos el vector de datos predichos y el vector de datos por validar.\n",
    "* La función debe imprimir las métricas del Error Cuadrático Promedio y $R2$.\n",
    "* Reporte las métricas para ambos modelos. En base a ello, seleccione el mejor modelo.\n",
    "\n",
    "---\n",
    "\n",
    "pto 1 y 2:\n",
    "* implementar\n",
    "def report_scores(y_pred, y_test):\n",
    "    print('Error Cuadrático Promedio:', mean_squared_error(y_test, y_pred))\n",
    "    print('R2:', r2_score(y_test, y_pred))\n",
    "\n",
    "pto 3:\n",
    "* Interpretar los resultados del pto anterior (markdown, explicación, ver clase del martes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Refactorización del modelo (1 puntos)\n",
    "* Genere una función llamada fetch_features que ingrese como argumentos la base de datos y el nombre del vector objetivo. El nombre del vector debe ser medv por defecto.\n",
    "* La función debe retornar una lista con las correlaciones entre cada atributo y el vector objetivo y su nombre.\n",
    "* Reporte brevemente cuales son los 6 atributos con una mayor correlación absoluta con medv (de mayor a menor correlación).\n",
    "---\n",
    "pto 1 y 2:\n",
    "* implementar (ver clase martes)\n",
    "def fetch_features(df, target='medv'):\n",
    "    corr = df.corr()\n",
    "    corr_target = corr[target].sort_values(ascending=False)\n",
    "    return corr_target.index[1:6], corr_target[1:6]\n",
    "    \n",
    "pto 3:\n",
    "* Interpretar los resultados del pto anterior (markdown, explicación, ver clase del martes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Refactorización del modelo predictivo (2 puntos)\n",
    "* Genere otros conjuntos de entrenamiento y validación en base a una matriz con los 6 atributos identificados en el ejercicio anterior, y el vector objetivo.\n",
    "* Entrene un modelo en base al mejor desempeño.\n",
    "* Reporte las métricas para el nuevo modelo.\n",
    "---\n",
    "pto 1:\n",
    "* Primero identificar cuales son las 6 variables con mayor correlación con medv (de mayor a menor correlación)\n",
    "* Segmentar data con X_train, X_test, y_train, y_test = train_test_split para las 6 columnas con mayor correlación con medv  \n",
    "\n",
    "pto 2:\n",
    "* Ir probando con las formas que vimos en clase: VIF, Pvalue (P > |t|), Cond number, AIC/BIC, \n",
    "Modelo full\n",
    "Modelo VIF\n",
    "Modelo pvalue\n",
    "Modelo con el intercepto\n",
    "* Si la solución pasa por usar el modulo sm, el seleccionar el mejor modelo pasa por usar .summary() y ver los 4 indicadores que mencionamos.\n",
    "* Si la solución para por usar sklearn, entonces el modelo de mejor desempeño es el modelo de las 6 columnas de mayor correlación con medv. \n",
    "\n",
    "pto 3:\n",
    "* usar report_scores del requerimiento 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción de casos (2 puntos): A continuación se generaron dos arrays que representan el peor escenario posible (worst_neighbor) y el mejor escenario posible (best_neighbor). Las variables representan, para cada caso, los valores de los siguientes atributos (en el mismo orden entregado): 'lstat', 'rm', 'ptratio', 'indus', 'tax', 'nox'. \n",
    "\n",
    "```python\n",
    "worst_neighbor = np.array([37.9, 12.6, 3.5, 27.7, 187, 0.87]).reshape(1,-1)\n",
    "best_neighbor = np.array([1.73, 22, 8.7, 0.46, 711, 0.38]).reshape(1,-1)\n",
    "```\n",
    "* Ingrese los arrays en el modelo entrenado en el ejercicio anterior, y reporte la\n",
    "predicción entregada por el modelo.\n",
    "---\n",
    "Lo que habría que hacer es utilizar esos valores para predecir el medv de cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9ccd8639d7ac6d8ae46f08631d02de0d1c9f4a08850208985333be71082afd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
