{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***SQL Para Data Science - Prueba***.\n",
    "### Nombre(s): Thomas Peet, Braulio Águila, Camilo Ramírez\n",
    "### Generación: G47\n",
    "### Profesores: José Terrazas - Sebastián Ulloa\n",
    "### Fecha: 14-11-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Instrucciones: Para poder correr el notebook es necesario renombrar el archivo .env_example a .env y modificar su contenido agregando los datos de conexión del usuario en postgres`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import helpers\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import  MeanMedianImputer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de la Base de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "user = os.getenv('POSTGRES_USER')\n",
    "password = os.getenv('POSTGRES_PASSWORD')\n",
    "host = os.getenv('POSTGRES_DBHOST')\n",
    "dbname = os.getenv('POSTGRES_DBNAME')\n",
    "drop_all = os.getenv('DROP_DATABASES')=='True'\n",
    "\n",
    "if drop_all:\n",
    "    conn = psycopg2.connect(user=user, host=host, port=5432, password=password, database='postgres')\n",
    "    conn.set_session(autocommit=True)\n",
    "    # Obtención de Cursor\n",
    "    cursor = conn.cursor()\n",
    "    # Eliminación de base de datos en caso de existir\n",
    "    cursor.execute(f\"DROP DATABASE IF EXISTS {dbname};\")\n",
    "    # Creacion de la base de datos en PostgreSQL\n",
    "    cursor.execute(f\"CREATE DATABASE {dbname};\")\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención y tratamiento de las columnas del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_cupid.csv')\n",
    "df.rename(columns = {'hispanic / latin':'hispanic_latin'}, inplace = True)\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "cols = df.columns.to_list()\n",
    "for index, col in enumerate(cols):\n",
    "    cols[index] +=' numeric'\n",
    "    \n",
    "cols = ', '.join(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=dbname, user=user, host=host, port=5432, password=password)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Eliminando las tablas train_cupid y test_cupid si existen.\n",
    "cursor.execute(\"DROP TABLE IF EXISTS train_cupid;\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS test_cupid;\")\n",
    "\n",
    "# Obteniendo un Cursor para las tablas\n",
    "name_table_train = f\"train_cupid ({cols})\"\n",
    "name_table_test = f\"test_cupid ({cols})\"\n",
    "\n",
    "# Creación de las sentecias para las tablas\n",
    "sqlTable_train = \"create table \"+name_table_train+';'\n",
    "sqlTable_test = \"create table \"+name_table_test+';'\n",
    "\n",
    "# Creando las tablas en PostgreSQL\n",
    "cursor.execute(sqlTable_train)\n",
    "cursor.execute(sqlTable_test)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de los datos del CSV a las Tablas creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_cupid.csv', 'r') as f:    \n",
    "    next(f) # Saltar la fila de los encabezados del CSV.\n",
    "    cursor.copy_from(f, 'train_cupid', sep=',')\n",
    "\n",
    "with open('test_cupid.csv', 'r') as f:    \n",
    "    next(f) # Saltar la fila de los encabezados del CSV.\n",
    "    cursor.copy_from(f, 'test_cupid', sep=',')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiendo columna indice a las tablas train_cupid y test_cupid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('ALTER TABLE train_cupid ADD indice SERIAL PRIMARY KEY;')\n",
    "cursor.execute('ALTER TABLE test_cupid ADD indice SERIAL PRIMARY KEY;')\n",
    "conn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando datos de train_cupid con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM train_cupid', conn, index_col='indice')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de la data para los 3 vectores objetivos: [**single**, **seeing_someone**, **available**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['single', 'seeing_someone', 'available']\n",
    "data = {}\n",
    "for target in targets:\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "    data[target] = {\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'X_train': X_train,\n",
    "        'X_valid': X_valid,\n",
    "        'y_train': y_train,\n",
    "        'y_valid': y_valid,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de los clasificadores a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    'm1' : GradientBoostingClassifier(random_state=42),\n",
    "    'm2' : AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=1, n_estimators=5), random_state=42, n_estimators=100, learning_rate=1),\n",
    "    'm3' : RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10),\n",
    "    'm4' : SVC(random_state=42, probability=True),\n",
    "    'm5' : DecisionTreeClassifier(random_state=42),\n",
    "    'm6' : LogisticRegression(random_state=42, C=0.01),\n",
    "    'm7' : BernoulliNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Pipeline(steps=[\n",
    "    ('num_imp', MeanMedianImputer(imputation_method='mean')),\n",
    "    ('ord', OrdinalEncoder(encoding_method='ordered', variables='age', ignore_format=True)),\n",
    "    ('sc', SklearnTransformerWrapper(StandardScaler(), variables=['age', 'height']))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit y serialización de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(target)\n",
    "    for modelo in modelos.values():\n",
    "        model_f = {'prep':prep, 'classifier':modelo}\n",
    "        helpers.report_performance(\n",
    "            # Esta función genera un pipeline con el subpipeline de preprocess y el modelo a entrenar.\n",
    "            helpers.pipeline_maker(**model_f),  \n",
    "            str(modelo.__class__).replace(\"'>\", '').split('.')[-1],\n",
    "            target,\n",
    "            data[target]['X_train'],\n",
    "            data[target]['X_valid'],\n",
    "            data[target]['y_train'],\n",
    "            data[target]['y_valid']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando datos de test_cupid con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_sql('SELECT * FROM test_cupid', conn, index_col='indice')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para insertar datos en una tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_values(conn, df, table):\n",
    "\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = ','.join(list(df.columns))\n",
    "    \n",
    "    # SQL query que se ejecutará\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    print(f'\\t\\t{query}')\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"\\t\\tthe dataframe is inserted\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries que se deben evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    'Query 1' : ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese'],\n",
    "    'Query 2' : ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york'],\n",
    "    'Query 3' : ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed'],\n",
    "    'Query 4' : ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de los modelos y guardado de las tablas tabulación cruzada de las predicciones en la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tINSERT INTO seeing_someone_svc_query4(taurus,indian,washington,income_between_50_75,hinduism,seeing_someone_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "available\n",
      "\tQuery 1(['atheism', 'asian', 'employed', 'pro_dogs', 'chinese'])\n",
      "\t\tModelo: ./models\\available__AdaBoostClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_adaboostclassifier_query1(atheism,asian,employed,pro_dogs,chinese,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__BernoulliNB__1411-20.pkl\n",
      "\t\tINSERT INTO available_bernoullinb_query1(atheism,asian,employed,pro_dogs,chinese,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__DecisionTreeClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_decisiontreeclassifier_query1(atheism,asian,employed,pro_dogs,chinese,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__GradientBoostingClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_gradientboostingclassifier_query1(atheism,asian,employed,pro_dogs,chinese,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__LogisticRegression__1411-20.pkl\n",
      "\t\tINSERT INTO available_logisticregression_query1(atheism,asian,employed,pro_dogs,chinese,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__RandomForestClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_randomforestclassifier_query1(atheism,asian,employed,pro_dogs,chinese,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__SVC__1411-20.pkl\n",
      "\t\tINSERT INTO available_svc_query1(atheism,asian,employed,pro_dogs,chinese,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\tQuery 2(['income_over_75', 'french', 'german', 'orientation_straight', 'new_york'])\n",
      "\t\tModelo: ./models\\available__AdaBoostClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_adaboostclassifier_query2(income_over_75,french,german,orientation_straight,new_york,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__BernoulliNB__1411-20.pkl\n",
      "\t\tINSERT INTO available_bernoullinb_query2(income_over_75,french,german,orientation_straight,new_york,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__DecisionTreeClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_decisiontreeclassifier_query2(income_over_75,french,german,orientation_straight,new_york,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__GradientBoostingClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_gradientboostingclassifier_query2(income_over_75,french,german,orientation_straight,new_york,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__LogisticRegression__1411-20.pkl\n",
      "\t\tINSERT INTO available_logisticregression_query2(income_over_75,french,german,orientation_straight,new_york,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__RandomForestClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_randomforestclassifier_query2(income_over_75,french,german,orientation_straight,new_york,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__SVC__1411-20.pkl\n",
      "\t\tINSERT INTO available_svc_query2(income_over_75,french,german,orientation_straight,new_york,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\tQuery 3(['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed'])\n",
      "\t\tModelo: ./models\\available__AdaBoostClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_adaboostclassifier_query3(education_undergrad_university,body_type_regular,pro_dogs,employed,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__BernoulliNB__1411-20.pkl\n",
      "\t\tINSERT INTO available_bernoullinb_query3(education_undergrad_university,body_type_regular,pro_dogs,employed,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__DecisionTreeClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_decisiontreeclassifier_query3(education_undergrad_university,body_type_regular,pro_dogs,employed,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__GradientBoostingClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_gradientboostingclassifier_query3(education_undergrad_university,body_type_regular,pro_dogs,employed,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__LogisticRegression__1411-20.pkl\n",
      "\t\tINSERT INTO available_logisticregression_query3(education_undergrad_university,body_type_regular,pro_dogs,employed,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__RandomForestClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_randomforestclassifier_query3(education_undergrad_university,body_type_regular,pro_dogs,employed,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__SVC__1411-20.pkl\n",
      "\t\tINSERT INTO available_svc_query3(education_undergrad_university,body_type_regular,pro_dogs,employed,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\tQuery 4(['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'])\n",
      "\t\tModelo: ./models\\available__AdaBoostClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_adaboostclassifier_query4(taurus,indian,washington,income_between_50_75,hinduism,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__BernoulliNB__1411-20.pkl\n",
      "\t\tINSERT INTO available_bernoullinb_query4(taurus,indian,washington,income_between_50_75,hinduism,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__DecisionTreeClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_decisiontreeclassifier_query4(taurus,indian,washington,income_between_50_75,hinduism,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__GradientBoostingClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_gradientboostingclassifier_query4(taurus,indian,washington,income_between_50_75,hinduism,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__LogisticRegression__1411-20.pkl\n",
      "\t\tINSERT INTO available_logisticregression_query4(taurus,indian,washington,income_between_50_75,hinduism,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__RandomForestClassifier__1411-20.pkl\n",
      "\t\tINSERT INTO available_randomforestclassifier_query4(taurus,indian,washington,income_between_50_75,hinduism,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n",
      "\t\tModelo: ./models\\available__SVC__1411-20.pkl\n",
      "\t\tINSERT INTO available_svc_query4(taurus,indian,washington,income_between_50_75,hinduism,available_yhat) VALUES %s\n",
      "\t\tthe dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "cursor_test = conn.cursor()\n",
    "for target in targets:\n",
    "    print(target)\n",
    "\n",
    "    # Segmentación de la data para el test\n",
    "    X_test = df_test.drop(columns=[target])\n",
    "    y_test = df_test[target]\n",
    "    \n",
    "    # Fecha de los modelos que se utilzaran. Formato: 1211-19 = 12 de Noviembre a las 19 horas. Se utilizará por defecto la fecha actual\n",
    "    fecha = datetime.datetime.now().strftime('%d%m-%H')\n",
    "    \n",
    "    # Listado de los modelos serializados\n",
    "    archivos_de_modelos = glob.glob(f'./models/{target}*_{fecha}.pkl')\n",
    "    \n",
    "    # Se evaluaran las 4 queries en los 7 modelos entrenados para predecir las 3 variables objetivos. Es decir se evaluaran 84 modelos.\n",
    "    for key, query in queries.items():\n",
    "        print(f'\\t{key}({query})')\n",
    "        for archivo_modelo in archivos_de_modelos:\n",
    "            print(f'\\t\\tModelo: {archivo_modelo}')\n",
    "\n",
    "            # Se hace una predicción sobre la data de test y se crea una tabla de tabulación cruzada sobre la data usando las variables de la query\n",
    "            queries_result_for_this_model, target_name, model_name = helpers.create_crosstab(archivo_modelo, X_test, y_test, query)\n",
    "            \n",
    "            # Se genera una tabla usando los datos del vector objetivo, nombre del modelo y query utilizada\n",
    "            nombre_tabla = f\"{target}_{model_name.lower()}_{key.lower().replace(' ','')}\"\n",
    "\n",
    "            # Las columnas que llevará esta tabla son las de la query más una variable y_hat que tendrá el promedio de la predicción para cada combinación\n",
    "            cols = ' numeric ,'.join(list(queries_result_for_this_model.index.names))+' numeric'\n",
    "            \n",
    "            # Se elimina si existe y se crea la tabla\n",
    "            cursor_test.execute(f\"DROP TABLE IF EXISTS {nombre_tabla};\")\n",
    "            cursor_test.execute(f\"CREATE TABLE {nombre_tabla} ({cols}, {target}_yhat numeric);\")\n",
    "            conn.commit()            \n",
    "\n",
    "            # Se insertan los valores de la tabulación cruzada en la tabla\n",
    "            execute_values(conn, queries_result_for_this_model.reset_index(), nombre_tabla)\n",
    "\n",
    "cursor_test.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88f3c7bcb2ddd9bbecb49b07cce2dbf7ad24b91a73731a897c825faf176394b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
