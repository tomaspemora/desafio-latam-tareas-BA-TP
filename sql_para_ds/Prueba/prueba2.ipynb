{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GCP_PROJECT_ID = v\n",
    "SERVICE_ACCOUNT_FILE = os.getenv('SERVICE_ACCOUNT_FILE')\n",
    "STORAGE_BUCKET_NAME = os.getenv('STORAGE_BUCKET_NAME')\n",
    "\n",
    "user = os.getenv('POSTGRES_USER')\n",
    "password = os.getenv('POSTGRES_PASSWORD')\n",
    "host = os.getenv('POSTGRES_DBHOST')\n",
    "dbname = os.getenv('POSTGRES_DBNAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de la Base de Datos\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(user=user, host=host, port=5432, password=password)\n",
    "conn.set_session(autocommit=True)\n",
    "\n",
    "# Obtención de Cursor\n",
    "cursor          = conn.cursor();\n",
    "name_Database   = \"prueba\";\n",
    "\n",
    "# Eliminación de base de datos en caso de existir\n",
    "cursor.execute(\"DROP DATABASE IF EXISTS prueba;\")\n",
    "\n",
    "# Creación de sentencia para la base de datos\n",
    "sqlCreateDatabase = \"create database \"+ name_Database +\";\"\n",
    "\n",
    "# Creacion de la base de datos en PostgreSQL\n",
    "cursor.execute(sqlCreateDatabase);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención y tratamiento de las columnas del CSV\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_cupid.csv')\n",
    "df.rename(columns = {'hispanic / latin':'hispanic_latin'}, inplace = True)\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "cols = df.columns.to_list()\n",
    "for index, col in enumerate(cols):\n",
    "    cols[index] +=' numeric'\n",
    "    \n",
    "cols = ', '.join(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de la tabla\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=dbname, user=user, host=host, port=5432, password=password)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Eliminando la tabla train_cupid si existe.\n",
    "cursor.execute(\"DROP TABLE IF EXISTS train_cupid;\")\n",
    "\n",
    "# Obteniendo un Cursor para la tabla\n",
    "name_table= f\"train_cupid ({cols})\"\n",
    "\n",
    "# Creación de la sentecia para la tabla \n",
    "sqlTable = \"create table \"+name_table+';'\n",
    "\n",
    "# Creando la tabla en PostgreSQL\n",
    "cursor.execute(sqlTable)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de los datos del CSV a la Tabla creada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_cupid.csv', 'r') as f:    \n",
    "    next(f) # Saltar la fila de los encabezados del CSV.\n",
    "    cursor.copy_from(f, 'train_cupid', sep=',')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Añadiendo columna indice a la tabla train_cupid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('ALTER TABLE train_cupid ADD indice SERIAL PRIMARY KEY;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando datos de train_cupid con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM train_cupid', conn, index_col='indice')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import  MeanMedianImputer\n",
    "from feature_engine.encoding import OrdinalEncoder, OneHotEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector objetivo: **single**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['single'])\n",
    "y = df.single\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1= GradientBoostingClassifier(random_state=42)\n",
    "m2= AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=1, n_estimators=5), random_state=42, n_estimators=100, learning_rate=1)\n",
    "m3= RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "m4= SVC(random_state=42, probability=True)\n",
    "m5= DecisionTreeClassifier(random_state=42)\n",
    "m6= LogisticRegression(random_state=42, C=0.01)\n",
    "m7= BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Pipeline(steps=[\n",
    "    ('num_imp', MeanMedianImputer(imputation_method='mean')),\n",
    "    ('ord', OrdinalEncoder(encoding_method='ordered', variables='age', ignore_format=True)),\n",
    "    ('sc', SklearnTransformerWrapper(StandardScaler(), variables=['age', 'height']))\n",
    "])\n",
    "\n",
    "prep.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'prep__num_imp__imputation_method': ['median', 'mean'],\n",
    "        #'prep__oe__encoding_method': ['ordered', 'arbitrary'],\n",
    "        'model__n_estimators': [10, 50, 100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "        'model__max_depth': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_m1 = Pipeline(steps=[\n",
    "    ('prep', prep),\n",
    "    ('model', m1)\n",
    "])\n",
    "\n",
    "search = GridSearchCV(pipe_m1, params, scoring='accuracy', cv= 5, n_jobs=-1)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)\n",
    "print(f'Best Score {search.best_score_}')\n",
    "print(f'Best Params {search.best_params_}')\n",
    "results = pd.DataFrame(search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88f3c7bcb2ddd9bbecb49b07cce2dbf7ad24b91a73731a897c825faf176394b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
