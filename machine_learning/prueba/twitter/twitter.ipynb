{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import CategoricalImputer, MeanMedianImputer\n",
    "from feature_engine.encoding import OrdinalEncoder, OneHotEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "# ------------------------------------------\n",
    "import nltk\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "## PROPIAS\n",
    "from utils import RemoveStopWords\n",
    "from utils import FeatureExtractionTwitts\n",
    "from utils import LemmantizerTransformer\n",
    "from utils import Vectorizer\n",
    "from utils import ColumnSelectedTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_tweets.csv', index_col = 0)\n",
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content.to_csv('raw_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_classes = {\n",
    "                    'happiness' : 'positiva',\n",
    "                    'surprise'  : 'positiva',\n",
    "                    'love'      : 'positiva',\n",
    "                    'fun'       : 'positiva',\n",
    "                    'relief'    : 'positiva',\n",
    "                    'enthusiasm': 'positiva',\n",
    "                    'worry'     : 'negativa',\n",
    "                    'hate'      : 'negativa',\n",
    "                    'sadness'   : 'negativa',\n",
    "                    'empty'     : 'negativa',\n",
    "                    'boredom'   : 'negativa',\n",
    "                    'anger'     : 'negativa',\n",
    "                    'neutral'   : 'neutral'\n",
    "                }\n",
    "neutral_class_name = 'neutral'\n",
    "target_var_name = 'sentiment'\n",
    "target_mapping = [('positiva',1),('negativa',0)]\n",
    "chars_to_replace = [\n",
    "                        ('ï¿½',''),\n",
    "                        ('&quot;',''),\n",
    "                        ('&lt;3','<3'), \n",
    "                        ('&lt;/3','</3'), \n",
    "                        ('&amp;','&'),\n",
    "                        ('&gt;','>'),\n",
    "                        ('&lt;','<')\n",
    "                    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_remapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34723</th>\n",
       "      <td>Happy Mama's day to all mothers</td>\n",
       "      <td>love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17493</th>\n",
       "      <td>@LysdelTellez I am lost. Please help me find a...</td>\n",
       "      <td>worry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20198</th>\n",
       "      <td>@BoomKatt yes yes I AM, networking whore to th...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>you@snapplynn Wish that would have been your t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>now i am doing the MicroEconomics project  iha...</td>\n",
       "      <td>worry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16469</th>\n",
       "      <td>I  do not want to work tomorrow!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36006</th>\n",
       "      <td>@KandyBee we shuld do  a dance like that its s...</td>\n",
       "      <td>fun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22647</th>\n",
       "      <td>Photo: Got my prints a few days ago, ready for...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>@tove_liden Thanks for the follow Tove!</td>\n",
       "      <td>fun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39364</th>\n",
       "      <td>@esmeeworld thanks</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  sentiment  \\\n",
       "34723                    Happy Mama's day to all mothers       love   \n",
       "17493  @LysdelTellez I am lost. Please help me find a...      worry   \n",
       "20198  @BoomKatt yes yes I AM, networking whore to th...  happiness   \n",
       "6855   you@snapplynn Wish that would have been your t...    neutral   \n",
       "5924   now i am doing the MicroEconomics project  iha...      worry   \n",
       "...                                                  ...        ...   \n",
       "16469                   I  do not want to work tomorrow!    sadness   \n",
       "36006  @KandyBee we shuld do  a dance like that its s...        fun   \n",
       "22647  Photo: Got my prints a few days ago, ready for...  happiness   \n",
       "21478            @tove_liden Thanks for the follow Tove!        fun   \n",
       "39364                                 @esmeeworld thanks    neutral   \n",
       "\n",
       "       sentiment_remapped  \n",
       "34723                   1  \n",
       "17493                   0  \n",
       "20198                   1  \n",
       "6855                    0  \n",
       "5924                    0  \n",
       "...                   ...  \n",
       "16469                   0  \n",
       "36006                   1  \n",
       "22647                   1  \n",
       "21478                   1  \n",
       "39364                   1  \n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "df_preprocess = Pipeline(steps=[\n",
    "                ('regroup_classes', \n",
    "                    FunctionTransformer(\n",
    "                        utils.multi_class_remapping, \n",
    "                        kw_args={\n",
    "                            'group_classes': groups_classes,\n",
    "                            'var_name': target_var_name,\n",
    "                            'neutral_class': neutral_class_name,\n",
    "                            'random_state': 42\n",
    "                            })),\n",
    "                ('encoding', FunctionTransformer(\n",
    "                        utils.target_encoding,\n",
    "                        kw_args={\n",
    "                            'column_to_encode': 'sentiment_remapped', 'mapping':target_mapping})),\n",
    "])\n",
    "\n",
    "df = df_preprocess.fit_transform(df) #\n",
    "df\n",
    "# Este debiese ser la primera transformación, no se si serializar esto o no pero habría que indicar que es necesario aplicarlo a df para poder continuar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los pipelines siguientes deberían vivir en un solo pipeline y al final aplicar fit_transform. Se debe serializar ese ultimo pipeline\n",
    "\n",
    "# hiperparametros posibles:\n",
    "# usar o no STOPWORDS\n",
    "# stemmers = 'ps' | 'wnl' | 'sno'\n",
    "stemmer = 'sno'\n",
    "wether_or_not_sw = True\n",
    "preprocessing = Pipeline(steps=[\n",
    "                ('rc', FunctionTransformer(utils.remove_chars, kw_args={'var_name': 'content', 'char_list': chars_to_replace})),\n",
    "                ('ra', FunctionTransformer(utils.remove_arrobas, kw_args= {'var_name':'content_remchars'})),\n",
    "                ('rl', FunctionTransformer(utils.remove_links, kw_args={'var_name': 'content_remchars_remarroba'})),\n",
    "                ('rsw', RemoveStopWords(text_columns = ['content_remchars_remarroba_remlinks'], bool_trans = wether_or_not_sw)),\n",
    "                ('lt', LemmantizerTransformer(text_columns = [f\"content_remchars_remarroba_remlinks{'_sw' if wether_or_not_sw else ''}\"], stemmer=stemmer)),\n",
    "                \n",
    "])\n",
    "\n",
    "# hiperparametros posibles:\n",
    "# min_df = 1,2,3...\n",
    "# max_df = 0.7 - 1.0\n",
    "# vect_type = 'count' | 'tfid'\n",
    "\n",
    "# Si se quiere ver los resultados de las limpiezas de los textos, comentar la linea de ColumnSelectedTransformer y luego ver el dataframe. También se pueden ver los reportes generados en csv y txt en la carpeta raíz.\n",
    "\n",
    "feature_extraction = Pipeline(steps=[\n",
    "                ('fet_1', FeatureExtractionTwitts(text_column=\"content\",features_to_extract=[\"arrobas_count\", \"hashtag_count\", \"is_reply\", \"is_rt\", \"twitt_length\"])),\n",
    "                ('fet_2', FeatureExtractionTwitts(text_column=f\"content_remchars_remarroba_remlinks{'_sw' if wether_or_not_sw else ''}_stemmer\",features_to_extract = [\"subjectivity\", \"polarity\"])),\n",
    "                ('ctr', Vectorizer(vect_type='tfid', text_column=f\"content_remchars_remarroba_remlinks{'_sw' if wether_or_not_sw else ''}_stemmer\", min_df=15, max_df=0.7, ngram_range=(1,3))),\n",
    "                ('ds', ColumnSelectedTransformer(vars_prefix='var_'))\n",
    "                \n",
    "])\n",
    "\n",
    "# joblib.load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnnb = MultinomialNB()\n",
    "clf1 = GaussianNB()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = SVC(random_state=42, probability=True)\n",
    "clf4 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "meta0 = LogisticRegression(random_state=42) # funciona particularmente bien stackeando xgboost\n",
    "meta1 = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "meta2 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# sería ideal probar:\n",
    "# GradientBoosting (Camilo)\n",
    "# HistGradientBoostingClassifier corre más rapido >10000 datos\n",
    "# VotingClassifier (Braulio)\n",
    "# StackingClassifier (Camilo)\n",
    "# Red Neuronal con Keras (KerasClassifier) (Thomas)\n",
    "# XGBoost, LightGBM, CatBoost (probar)\n",
    "\n",
    "estimators = [('gnb', clf1), ('gbc', clf4)]\n",
    "\n",
    "# final estimator: metaestimator\n",
    "st_1 = StackingClassifier(estimators=estimators,\n",
    "                        final_estimator=meta2,\n",
    "                        cv=5)\n",
    "\n",
    "params = {\n",
    "    'preprocessing__lt__stemmer': ['sno', 'ps', 'wnl'],\n",
    "    'feature_extraction__ctr__vect_type': ['tfid'],\n",
    "    'feature_extraction__ctr__min_df': [5, 10, 15],\n",
    "    'model__n_estimators': [50, 100, 500],\n",
    "    'model__max_depth': [5, 10, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(pipe, X_train, X_test, y_train, y_test):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_train = pipe.predict(X_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(classification_report(y_train, y_pred_train, digits=4))\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['content']]\n",
    "y = df.sentiment_remapped\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('feature_extraction', feature_extraction),\n",
    "    ('model', meta2)\n",
    "])\n",
    "\n",
    "# train_function(pipe, X_train, X_test, y_train, y_test)\n",
    "\n",
    "search = GridSearchCV(pipe, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_, search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['feature_extraction']['ds'].vars_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.hist(X_tr['var_subjectivity'], bins=50, fc=(1, 0, 0, 0.5))\n",
    "# plt.hist(X_tr['var_polarity'], bins=50, fc=(0, 0, 1, 0.5))\n",
    "# plt.title('Sentiment analysis')\n",
    "# plt.xlabel('Polarity')\n",
    "# plt.ylabel('Subjectivity')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.hist(X_tr['var_twit_length'], bins=30, fc=(1, 0, 0, 0.5))\n",
    "# plt.title('Twits length')\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9ccd8639d7ac6d8ae46f08631d02de0d1c9f4a08850208985333be71082afd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
