{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import CategoricalImputer, MeanMedianImputer\n",
    "from feature_engine.encoding import OrdinalEncoder, OneHotEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34723</th>\n",
       "      <td>Happy Mama's day to all mothers</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17493</th>\n",
       "      <td>@LysdelTellez I am lost. Please help me find a...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20198</th>\n",
       "      <td>@BoomKatt yes yes I AM, networking whore to th...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>you@snapplynn Wish that would have been your t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>now i am doing the MicroEconomics project  iha...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16469</th>\n",
       "      <td>I  do not want to work tomorrow!</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36006</th>\n",
       "      <td>@KandyBee we shuld do  a dance like that its s...</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22647</th>\n",
       "      <td>Photo: Got my prints a few days ago, ready for...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>@tove_liden Thanks for the follow Tove!</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39364</th>\n",
       "      <td>@esmeeworld thanks</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  sentiment\n",
       "34723                    Happy Mama's day to all mothers       love\n",
       "17493  @LysdelTellez I am lost. Please help me find a...      worry\n",
       "20198  @BoomKatt yes yes I AM, networking whore to th...  happiness\n",
       "6855   you@snapplynn Wish that would have been your t...    neutral\n",
       "5924   now i am doing the MicroEconomics project  iha...      worry\n",
       "...                                                  ...        ...\n",
       "16469                   I  do not want to work tomorrow!    sadness\n",
       "36006  @KandyBee we shuld do  a dance like that its s...        fun\n",
       "22647  Photo: Got my prints a few days ago, ready for...  happiness\n",
       "21478            @tove_liden Thanks for the follow Tove!        fun\n",
       "39364                                 @esmeeworld thanks    neutral\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_tweets.csv', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ....\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', download_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 34723 to 39364\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   content    30000 non-null  object\n",
      " 1   sentiment  30000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 703.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "len(words.words())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import stopwords\n",
    "len(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x2 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "X = vec.fit_transform(df)\n",
    "vec.get_feature_names_out()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34723</th>\n",
       "      <td>Happy Mama's day to all mothers</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17493</th>\n",
       "      <td>@LysdelTellez I am lost. Please help me find a...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20198</th>\n",
       "      <td>@BoomKatt yes yes I AM, networking whore to th...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>you@snapplynn Wish that would have been your t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>now i am doing the MicroEconomics project  iha...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16469</th>\n",
       "      <td>I  do not want to work tomorrow!</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36006</th>\n",
       "      <td>@KandyBee we shuld do  a dance like that its s...</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22647</th>\n",
       "      <td>Photo: Got my prints a few days ago, ready for...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>@tove_liden Thanks for the follow Tove!</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39364</th>\n",
       "      <td>@esmeeworld thanks</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  sentiment\n",
       "34723                    Happy Mama's day to all mothers       love\n",
       "17493  @LysdelTellez I am lost. Please help me find a...      worry\n",
       "20198  @BoomKatt yes yes I AM, networking whore to th...  happiness\n",
       "6855   you@snapplynn Wish that would have been your t...    neutral\n",
       "5924   now i am doing the MicroEconomics project  iha...      worry\n",
       "...                                                  ...        ...\n",
       "16469                   I  do not want to work tomorrow!    sadness\n",
       "36006  @KandyBee we shuld do  a dance like that its s...        fun\n",
       "22647  Photo: Got my prints a few days ago, ready for...  happiness\n",
       "21478            @tove_liden Thanks for the follow Tove!        fun\n",
       "39364                                 @esmeeworld thanks    neutral\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pase\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('./corpora/stopwords')\n",
    "    print('pase')\n",
    "except LookupError:\n",
    "    nltk.download('words',download_dir='.')\n",
    "    print('descargue')\n",
    "stopwords.words('english');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'content'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import RemoveStopWords\n",
    "\n",
    "rsw = RemoveStopWords(columns = ['content'])\n",
    "df = rsw.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15681\n",
       "1     13635\n",
       "2       558\n",
       "3        76\n",
       "4        28\n",
       "5        13\n",
       "6         5\n",
       "9         1\n",
       "10        1\n",
       "7         1\n",
       "8         1\n",
       "Name: arrobas_count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import FeatureExtractionTwitts\n",
    "\n",
    "fet = FeatureExtractionTwitts(twit_text_column=\"content_min\", features_to_extract = [\"arrobas_count\", \"hashtag_count\", \"is_reply\"])\n",
    "df = fet.transform(df)\n",
    "df.arrobas_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29379\n",
       "1      538\n",
       "2       63\n",
       "3       14\n",
       "9        3\n",
       "5        1\n",
       "7        1\n",
       "4        1\n",
       "Name: hashtag_count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hashtag_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16512\n",
       "1    13488\n",
       "Name: is_reply, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_reply.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ps</th>\n",
       "      <th>sno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [initial, lemma, ps, sno]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ps</th>\n",
       "      <th>sno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy mama's day mothers</td>\n",
       "      <td>happy mama 's day mother</td>\n",
       "      <td>happi mama 's day mother</td>\n",
       "      <td>happi mama 's day mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@lysdeltellez i lost. please help find good home.</td>\n",
       "      <td>@ lysdeltellez i lost . please help find good ...</td>\n",
       "      <td>@ lysdeltellez i lost . pleas help find good h...</td>\n",
       "      <td>@ lysdeltellez i lost . pleas help find good h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@boomkatt yes yes i am, networking whore fulle...</td>\n",
       "      <td>@ boomkatt yes yes i am , networking whore ful...</td>\n",
       "      <td>@ boomkatt ye ye i am , network whore fullest ...</td>\n",
       "      <td>@ boomkatt yes yes i am , network whore fulles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you@snapplynn wish would tweet followed me.</td>\n",
       "      <td>you @ snapplynn wish would tweet followed me .</td>\n",
       "      <td>you @ snapplynn wish would tweet follow me .</td>\n",
       "      <td>you @ snapplynn wish would tweet follow me .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microeconomics project  ihate subject &amp;amp; be...</td>\n",
       "      <td>microeconomics project ihate subject &amp; amp ; b...</td>\n",
       "      <td>microeconom project ihat subject &amp; amp ; besid...</td>\n",
       "      <td>microeconom project ihat subject &amp; amp ; besid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29993</th>\n",
       "      <td>i  want work tomorrow!</td>\n",
       "      <td>i want work tomorrow !</td>\n",
       "      <td>i want work tomorrow !</td>\n",
       "      <td>i want work tomorrow !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>@kandybee shuld  dance like seriously best thi...</td>\n",
       "      <td>@ kandybee shuld dance like seriously best thi...</td>\n",
       "      <td>@ kandybe shuld danc like serious best thing h...</td>\n",
       "      <td>@ kandybe shuld danc like serious best thing h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>photo: got prints days ago, ready norskart exh...</td>\n",
       "      <td>photo : got print day ago , ready norskart exh...</td>\n",
       "      <td>photo : got print day ago , readi norskart exh...</td>\n",
       "      <td>photo : got print day ago , readi norskart exh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>@tove_liden thanks follow tove!</td>\n",
       "      <td>@ tove_liden thanks follow tove !</td>\n",
       "      <td>@ tove_liden thank follow tove !</td>\n",
       "      <td>@ tove_liden thank follow tove !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>@esmeeworld thanks</td>\n",
       "      <td>@ esmeeworld thanks</td>\n",
       "      <td>@ esmeeworld thank</td>\n",
       "      <td>@ esmeeworld thank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29998 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 initial  \\\n",
       "0                               happy mama's day mothers   \n",
       "1      @lysdeltellez i lost. please help find good home.   \n",
       "2      @boomkatt yes yes i am, networking whore fulle...   \n",
       "3            you@snapplynn wish would tweet followed me.   \n",
       "4      microeconomics project  ihate subject &amp; be...   \n",
       "...                                                  ...   \n",
       "29993                             i  want work tomorrow!   \n",
       "29994  @kandybee shuld  dance like seriously best thi...   \n",
       "29995  photo: got prints days ago, ready norskart exh...   \n",
       "29996                    @tove_liden thanks follow tove!   \n",
       "29997                                 @esmeeworld thanks   \n",
       "\n",
       "                                                   lemma  \\\n",
       "0                              happy mama 's day mother    \n",
       "1      @ lysdeltellez i lost . please help find good ...   \n",
       "2      @ boomkatt yes yes i am , networking whore ful...   \n",
       "3        you @ snapplynn wish would tweet followed me .    \n",
       "4      microeconomics project ihate subject & amp ; b...   \n",
       "...                                                  ...   \n",
       "29993                            i want work tomorrow !    \n",
       "29994  @ kandybee shuld dance like seriously best thi...   \n",
       "29995  photo : got print day ago , ready norskart exh...   \n",
       "29996                 @ tove_liden thanks follow tove !    \n",
       "29997                               @ esmeeworld thanks    \n",
       "\n",
       "                                                      ps  \\\n",
       "0                              happi mama 's day mother    \n",
       "1      @ lysdeltellez i lost . pleas help find good h...   \n",
       "2      @ boomkatt ye ye i am , network whore fullest ...   \n",
       "3          you @ snapplynn wish would tweet follow me .    \n",
       "4      microeconom project ihat subject & amp ; besid...   \n",
       "...                                                  ...   \n",
       "29993                            i want work tomorrow !    \n",
       "29994  @ kandybe shuld danc like serious best thing h...   \n",
       "29995  photo : got print day ago , readi norskart exh...   \n",
       "29996                  @ tove_liden thank follow tove !    \n",
       "29997                                @ esmeeworld thank    \n",
       "\n",
       "                                                     sno  \n",
       "0                              happi mama 's day mother   \n",
       "1      @ lysdeltellez i lost . pleas help find good h...  \n",
       "2      @ boomkatt yes yes i am , network whore fulles...  \n",
       "3          you @ snapplynn wish would tweet follow me .   \n",
       "4      microeconom project ihat subject & amp ; besid...  \n",
       "...                                                  ...  \n",
       "29993                            i want work tomorrow !   \n",
       "29994  @ kandybe shuld danc like serious best thing h...  \n",
       "29995  photo : got print day ago , readi norskart exh...  \n",
       "29996                  @ tove_liden thank follow tove !   \n",
       "29997                                @ esmeeworld thank   \n",
       "\n",
       "[29998 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def stemSentence(sentence, stemmer):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(stemmer(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "    nltk.data.find('corpora/omw-1.4.zip/omw-1.4/')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "fd = pd.DataFrame([], columns=['initial', 'lemma', 'ps', 'sno'])\n",
    "display(fd)\n",
    "c=0\n",
    "for sentence in df.content_min:\n",
    "    sno_word = stemSentence(sentence, sno.stem)\n",
    "    ps_word = stemSentence(sentence, ps.stem)\n",
    "    lemma_word = stemSentence(sentence, lemma.lemmatize)\n",
    "    # sno_word = sno.stem(word)\n",
    "    # ps_word = ps.stem(word)\n",
    "    # lemma_word = lemma.lemmatize(word)\n",
    "    if sentence != sno_word or sentence != lemma_word or sentence != ps_word:\n",
    "        fd = pd.concat([fd,pd.DataFrame([[sentence, lemma_word, ps_word, sno_word]], index=[c], columns=['initial', 'lemma', 'ps', 'sno'])])\n",
    "        c+=1\n",
    "        # if c > 10000:\n",
    "        #     break;\n",
    "fd\n",
    "\n",
    "\n",
    "# Nota: creo que deberíamos aplicar lemma/stem primero y despues stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9ccd8639d7ac6d8ae46f08631d02de0d1c9f4a08850208985333be71082afd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
