{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Machine Learning Prueba 2 - Analizando los crímenes en la Ciudad de Nueva York***.\n",
    "### Nombre(s): Thomas Peet, Braulio Águila, Camilo Ramírez\n",
    "### Generación: G47\n",
    "### Profesores: Alfonso Tobar - Sebastián Ulloa\n",
    "### Fecha: 06-10-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Contexto*\n",
    "En esta ocasión trabajaremos con datos públicos del departamento de policía de New York.    \n",
    "El dataset es llamado stop_and_frisk_data y contiene información sobre interrogaciones    \n",
    "y detenciones realizadas por el departamento de policía de NY en la vía pública. El    \n",
    "diccionario de atributos se encuentra en el archivo 2009 SQF File Spec.xls.    \n",
    "Para todo nuestro estudio utilizaremos los datos correspondientes al año 2009 como    \n",
    "conjunto de entrenamiento y los datos del 2010 como conjunto de pruebas. Hay que hacer    \n",
    "notar que los datos que estamos utilizando son un muestreo del de la cantidad de registros    \n",
    "reales que contiene el dataset, esta decisión fue tomada debido a los largos tiempos de    \n",
    "entrenamiento y procesamiento que requiere el volumen de datos reales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Objetivos*\n",
    "Para alcanzar el objetivo general, su trabajo se puede desagregar en los siguientes puntos:  \n",
    "\n",
    "1. Debe analizar de forma exploratoria los atributos. Reporte la cantidad de datos    \n",
    "perdidos y presente su esquema de recodificación. Tenga presente que lo que    \n",
    "observe en el análisis exploratorio debe guiar su proceso de ingeniería de atributos,    \n",
    "por lo que se le recomienda que piense en aspectos de las variables involucradas     \n",
    "que puedan afectar el proceso mencionado.\n",
    "\n",
    "2. Reporte la probabilidad de que un individuo sea arrestado en uno de los cinco  \n",
    "barrios, condicional al género y a la raza. Concluya, ¿qué implicancias éticas tienen  \n",
    "algunas conclusiones de lo que observa?.\n",
    "\n",
    "3. Entregue un modelo predictivo que prediga efectivamente si un determinado  \n",
    "procedimiento concluirá en un arresto o no. Para ello, guíate por los siguientes  \n",
    "lineamientos:  \n",
    "    - Entrene por lo menos 3 modelos que sean capaces de predecir si se  \n",
    "producirá un arresto o no. Una vez que encuentre un modelo satisfactorio,  \n",
    "reporte al menos dos métricas de desempeño.  \n",
    "    - Refine aquellos atributos relevantes con alguna estrategia que crea  \n",
    "conveniente y reporte por lo menos 5 atributos relevantes para realizar la  \n",
    "predicción.\n",
    "\n",
    "4. Genere al menos cinco modelos predictivos que permitan determinar si el  \n",
    "procedimiento policial concluirá en alguna acción violenta.  \n",
    "○ Para ello, debe generar un nuevo atributo como vector objetivo que indique  \n",
    "cuándo hubo violencia o no. Éste debe ser creado a partir de atributos  \n",
    "existentes que indiquen el tipo de violencia.\n",
    "  \n",
    "5. Seleccione los 2 mejores modelos, serialicelos y envíalos a evaluación. Recuerde que  \n",
    "el modelo serializado debe ser posterior al fit, para poder ejecutar predict en los  \n",
    "nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>#### Tipo de problema a resolver:\n",
    "- De acuerdo con el enunciado y una revisión preliminar de los datos entregados, ambas problemáticas planteadas,  \n",
    "el hecho de que ocurra o no un arresto, y de que un procedimiento policial es o no violento, corresponden a   \n",
    "problemas de **clasificación**, ya que ambas variables objetivos son discretas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>#### Tipo de métricas a implementar:\n",
    "- Las métricas que se utilizarán para la división de muestras corresponden a :\n",
    "- Tipo de preprocesamiento: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>#### Modelos (5) con gridsearch e hiperparamétros tentativos/definitivos:\n",
    "- Modelo 1:\n",
    "- Modelo 2:\n",
    "- Modelo 3:\n",
    "- Modelo 4:\n",
    "- Modelo 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>#### Comportamiento de variables objetivo (recodificados):\n",
    "- Variable objetivo 1: procedimiento policial en el que ocurre o no un arresto (\"arstmade\")\n",
    "- Variable objetivo 2: procedimiento policial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import CategoricalImputer, MeanMedianImputer\n",
    "from feature_engine.encoding import OrdinalEncoder, OneHotEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "#from feature engine drop features ----> sacar features para el pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "from pathlib import Path\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "#import shapely\n",
    "#import folium \n",
    "import pyproj\n",
    "import helpers as hp\n",
    "import preproc_nyc_sqf_V2 as preproc\n",
    "import contextily as cx\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Dataset interrogaciones/detenciones Policía de Nueva York - 2009***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pct</th>\n",
       "      <th>ser_num</th>\n",
       "      <th>datestop</th>\n",
       "      <th>timestop</th>\n",
       "      <th>recstat</th>\n",
       "      <th>inout</th>\n",
       "      <th>trhsloc</th>\n",
       "      <th>perobs</th>\n",
       "      <th>crimsusp</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>addrpct</th>\n",
       "      <th>sector</th>\n",
       "      <th>beat</th>\n",
       "      <th>post</th>\n",
       "      <th>xcoord</th>\n",
       "      <th>ycoord</th>\n",
       "      <th>dettypcm</th>\n",
       "      <th>linecm</th>\n",
       "      <th>detailcm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178048</th>\n",
       "      <td>2009</td>\n",
       "      <td>41</td>\n",
       "      <td>1779</td>\n",
       "      <td>4032009</td>\n",
       "      <td>130</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CPW</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>41</td>\n",
       "      <td>G</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>1013067</td>\n",
       "      <td>0238633</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498873</th>\n",
       "      <td>2009</td>\n",
       "      <td>108</td>\n",
       "      <td>5805</td>\n",
       "      <td>10292009</td>\n",
       "      <td>1050</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BURG</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>108</td>\n",
       "      <td>J</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1012043</td>\n",
       "      <td>0212157</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463573</th>\n",
       "      <td>2009</td>\n",
       "      <td>43</td>\n",
       "      <td>8340</td>\n",
       "      <td>10062009</td>\n",
       "      <td>1450</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MISD</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>43</td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1017599</td>\n",
       "      <td>0240200</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43626</th>\n",
       "      <td>2009</td>\n",
       "      <td>77</td>\n",
       "      <td>932</td>\n",
       "      <td>1232009</td>\n",
       "      <td>1843</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MIS</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>77</td>\n",
       "      <td>J</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>1002625</td>\n",
       "      <td>0183442</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563921</th>\n",
       "      <td>2009</td>\n",
       "      <td>110</td>\n",
       "      <td>11224</td>\n",
       "      <td>12132009</td>\n",
       "      <td>1655</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CPW</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td>H</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1024535</td>\n",
       "      <td>0209890</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  pct  ser_num  datestop  timestop recstat inout trhsloc  perobs  \\\n",
       "178048  2009   41     1779   4032009       130       A     O       P     1.0   \n",
       "498873  2009  108     5805  10292009      1050       A     O       P     3.0   \n",
       "463573  2009   43     8340  10062009      1450       1     O       P     1.0   \n",
       "43626   2009   77      932   1232009      1843       A     O       P     5.0   \n",
       "563921  2009  110    11224  12132009      1655       A     O       P     3.0   \n",
       "\n",
       "       crimsusp  ...  zip addrpct sector beat post   xcoord   ycoord dettypcm  \\\n",
       "178048      CPW  ...           41      G    7       1013067  0238633       CM   \n",
       "498873     BURG  ...          108      J            1012043  0212157       CM   \n",
       "463573     MISD  ...           43      E            1017599  0240200       CM   \n",
       "43626       MIS  ...           77      J    4   35  1002625  0183442       CM   \n",
       "563921      CPW  ...          110      H            1024535  0209890       CM   \n",
       "\n",
       "        linecm  detailcm  \n",
       "178048       1        20  \n",
       "498873       1        14  \n",
       "463573       1        20  \n",
       "43626        1        24  \n",
       "563921       1        20  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2009 = pd.read_csv('2009_1perc.csv', index_col=0)\n",
    "df2009.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5812, 111)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Revisión de registros y features de df1:\n",
    "df2009.shape #5812 registros y 111 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de los datasets para los 2 problemas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definición target y_1\n",
    "y_1 = df2009.arstmade\n",
    "\n",
    "## Transformación target y_2\n",
    "var_pf = df2009.columns[np.where([i[0:2]=='pf' for i in df2009.columns.tolist()])]. tolist()\n",
    "u = df2009[var_pf]\n",
    "y_2 = [int(np.isin([\"Y\"], u.iloc[i].values.tolist())[0]) for i in range(0,len(u))]\n",
    "\n",
    "## Predictores para y_1 e y_2: hay un subconjunto de potenciales predictores para y_1 y otro para y_2\n",
    "x_1 = df2009.drop(columns=['arstmade'])\n",
    "\n",
    "var_eliminar_pf = [\"pf_baton\", \"pf_hcuff\", \"pf_pepsp\", \"pf_other\", \"pf_ptwep\", \"pf_drwep\", \"pf_wall\", \"pf_hands\", \"pf_grnd\"] #9 variables eliminadas\n",
    "x_2 = df2009.drop(columns = var_eliminar_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perobs', 'xcoord', 'ycoord']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Pipeline.transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tomas\\Desktop\\Tareas Data Science - Desafío Latam\\machine_learning\\prueba\\crimenes\\crimenesBA2.ipynb Celda 14\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/Desktop/Tareas%20Data%20Science%20-%20Desaf%C3%ADo%20Latam/machine_learning/prueba/crimenes/crimenesBA2.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m X_train_1, X_test_1, y_train_1, y_test_1 \u001b[39m=\u001b[39m train_test_split(x_1, y_1, test_size\u001b[39m=\u001b[39m\u001b[39m.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/Desktop/Tareas%20Data%20Science%20-%20Desaf%C3%ADo%20Latam/machine_learning/prueba/crimenes/crimenesBA2.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m preprocess\u001b[39m.\u001b[39mfit(X_train_1,y_train_1)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tomas/Desktop/Tareas%20Data%20Science%20-%20Desaf%C3%ADo%20Latam/machine_learning/prueba/crimenes/crimenesBA2.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m x_tr, y_1 \u001b[39m=\u001b[39m preprocess\u001b[39m.\u001b[39;49mtransform(x_1,y_1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/Desktop/Tareas%20Data%20Science%20-%20Desaf%C3%ADo%20Latam/machine_learning/prueba/crimenes/crimenesBA2.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m variables_categoricas \u001b[39m=\u001b[39m preprocess[\u001b[39m'\u001b[39m\u001b[39mcsd\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msuitable_categorical_attributes\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/Desktop/Tareas%20Data%20Science%20-%20Desaf%C3%ADo%20Latam/machine_learning/prueba/crimenes/crimenesBA2.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m oe \u001b[39m=\u001b[39m OrdinalEncoder(encoding_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mordered\u001b[39m\u001b[39m'\u001b[39m,variables \u001b[39m=\u001b[39m variables_categoricas)\n",
      "\u001b[1;31mTypeError\u001b[0m: Pipeline.transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "#Se utiliza función entregada para limpieza preliminar de la data, se obtiene un df nuevo procesado y dos listas:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "proc_df, suitable_categorical_attributes, suitable_numerical_attributes = preproc.create_suitable_dataframe(df2009)\n",
    "warnings.filterwarnings(\"always\")\n",
    "proc_df #este nuevo dataframe, estas constituido de 69 variables categóricas y 2 númericas sintéticas (\"meters\", \"month\")\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import CreateSuitableDataframeTransformer\n",
    "\n",
    "preprocess = Pipeline(steps=[\n",
    "    ('csd', CreateSuitableDataframeTransformer())\n",
    "    # ('ce', CriterioExperto())\n",
    "])\n",
    "\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(x_1, y_1, test_size=.2, random_state=42)\n",
    "\n",
    "preprocess.fit(X_train_1,y_train_1)\n",
    "x_tr, y_1 = preprocess.transform(x_1,y_1)\n",
    "variables_categoricas = preprocess['csd'].suitable_categorical_attributes\n",
    "oe = OrdinalEncoder(encoding_method='ordered',variables = variables_categoricas)\n",
    "x_tr_oe = oe.fit_transform(x_tr,y_1)\n",
    "x_tr_oe\n",
    "\n",
    "\n",
    "\n",
    "# preprocess.transform(X_1_test, y_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess['csd'].preserve_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitable_numerical_attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>#### Exploración variable objetivo 1 (\"arstmade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df.arstmade.value_counts() #oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualización de el vector objetivo:\n",
    "sns.histplot(proc_df, x=\"arstmade\"); # Categoría uno muchos menos casos que categoría 0.\n",
    "plt.title(\"Vector objetivo : arstmade\")\n",
    "plt.xlabel(\"clases\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>#### Exploración variable objetivo 2 (\"violencia física en arresto\") --- Necesita ser recodificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recodificando variable objetivo 2:\n",
    "\n",
    "var_pf = proc_df.columns[np.where([i[0:2]=='pf' for i in proc_df.columns.tolist()])]. tolist()\n",
    "u = proc_df[var_pf]\n",
    "u[\"var_pf\"] = [int(np.isin([\"Y\"], u.iloc[i].values.tolist())[0]) for i in range(0,len(u))]\n",
    "\n",
    "proc_df.insert(proc_df.shape[1],\"var_pf\", u[\"var_pf\"])\n",
    "proc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp.cat_num_rate_analysis(proc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considerar variables relevantes para modelos de procedimiento que concluye en arresto y/o procedimiento que concluye en situación violenta:\n",
    "#redinir variable \"othpers\" (esta mál escrita con respecto a la planilla)\n",
    "mantener = [\"var_pf\", \"rf_vcrim\", \"rf_othsw\t\", \"cs_descr\", \"arstmade\", \"contrabn\",\n",
    "\"pistol\", \"riflshot\", \"asltweap\", \"knifcuti\", \"othrweap\", \"rf_vcact\", \"ac_evasv\", \"offshld\", \"cs_drgtr\",\n",
    "\"sb_outln\",\t\"sb_hdobj\", \"ac_time\", \"rf_knowl\", \"ac_assoc\", \"rf_rfcmp\", \"cs_vcrim\", \"ac_incid\"\n",
    "\"rf_verbl\", \"sex\", \"city\", \"race\", \"month\", \"xcoord\", \"ycoord\", \"sb_admis\"]\n",
    "var_eliminar_pf = [\"pf_baton\", \"pf_hcuff\", \"pf_pepsp\", \"pf_other\", \"pf_ptwep\", \n",
    "                    \"pf_drwep\", \"pf_wall\", \"pf_hands\", \"pf_grnd\"] #9 variables eliminadas\n",
    "var_eliminar_others = [\"ac_rept\", \"ac_inves\", \"ac_proxm\", \"cs_casng\", \"cs_lkout\", \"explnstp\", \n",
    "\"sumissue\", \"offunif\", \"officrid\", \"frisked\", \"searched\", \"cs_cloth\", \"offverb\", \"rf_furt\",\n",
    "\"sb_other\", \"ac_other\", \"rf_bulg\", \"cs_furtv\", \"recstat\", \"cs_bulge\", \"cs_other\"\n",
    "\"trhsloc\", \"build\", \"beat\", \"post\",\"rf_attir\", \"cs_objcs\",\"eyecolor\", \"haircolr\", \"sector\" ]\n",
    "pendientes = [\"radio\", \"inout\", \"othpers\", \"ac_stsnd\", \"ac_cgdir\", \"meters\", \"typeofid\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable \"sex\" necesita ser recodificada (random choice?) para tener una variable categórica binaria en ejercicio de probabilidades.\n",
    "#recodificar city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar variables (Considerar drop_features)\n",
    "#dropna(axis = 1, inplace= True)\n",
    "#df_na = df1.dropna(how=\"all\", axis=1)  \n",
    "#dfnan = df1.dropna(subset=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formato para definir variables elegidas posterior al filtro\n",
    "\n",
    "# # ***Listado de variables***:\n",
    "# * `age`: Edad del individuo.\n",
    "# * `workclass`: Naturaleza de la organización que emplea al individuo.\n",
    "# * `education`: Nivel educacional del individuo:\n",
    "#     | Variable          | Explicación                       |\n",
    "#     | ----------------- | ------------------                |\n",
    "#     | __Bachelors__     | (Licenciado)                      |\n",
    "#     | __Some-college__  | (Superior incompleta)             |\n",
    "#     | __11th__          | (3ro medio)                       |\n",
    "#     | __HS-grad__       | (Secundaria completa)             |\n",
    "#     | __Prof-school__   | (Escuela profesional)             |\n",
    "#     | __ssoc-acdm__     | (Técnico superior administrativo) |\n",
    "#     | __Assoc-voc__     | (Técnico superior vocacional)     |\n",
    "#     | __9th__           | (1ro medio)                       |\n",
    "#     | __7th-8th__       | (7mo-8vo)                         |\n",
    "#     | __12th__          | (4to medio)                       |\n",
    "#     | __Masters__       | (Maestría de postgrado)           |\n",
    "#     | __1st-4th__       | (1ro-4to básico)                  |\n",
    "#     | __10th__          | (2do medio)                       |\n",
    "#     | __Doctorate__     | (Doctorado)                       |\n",
    "#     | __5th-6th__       | (5to-6to)                         |\n",
    "#     | __Preschool__     | (Preescolar).                     |\n",
    "     \n",
    "#     <br>  \n",
    "    \n",
    "# * `capital-gains`: Ingresos generados por inversiones fuera del trabajo asalariado\n",
    "# * `capital-losses`: Pérdidas generadas por inversiones fuera del trabajo asalariado.\n",
    "# * `fnlwgt`: Ponderador muestral.\n",
    "# * `marital-status`: Estado civil del individuo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa\n",
    "gdf = gpd.GeoDataFrame(proc_df, geometry=gpd.points_from_xy(proc_df.xcoord, proc_df.ycoord))\n",
    "df = gpd.read_file(gpd.datasets.get_path(\"nybb\"))\n",
    "df_wm = df.to_crs(epsg=3857)\n",
    "ax = df.plot(figsize=(15,10), alpha=0.5, edgecolor = \"k\")\n",
    "cx.add_basemap(ax,crs=df.crs, zoom =11, source=cx.providers.Stamen.TonerLite)\n",
    "#cx.add_basemap(ax, source=cx.providers.Stamen.TonerLabels)\n",
    "gdf.plot(ax=ax, color= \"red\", edgecolor = \"black\", markersize = 4)\n",
    "\n",
    "\n",
    "#Incorporar al código de arriba para poder plotear variable objetivo:\n",
    "# fig,ax = plt.subplots(1, 1) #plt.figure(figsize=(10,8))\n",
    "# fig.set_size_inches(25, 25)\n",
    "# df2009map[df2009map.arstmade == \"N\"].plot(color=\"red\", ax=ax, markersize = 1)\n",
    "# df2009map[df2009map.arstmade == \"Y\"].plot(ax=ax,  markersize = 12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función transformar x,y to lon, lat:\n",
    "def xy_to_latlon(x,y):\n",
    "    source_crs = 'epsg:2263' # Coordinate system of the file\n",
    "    target_crs = 'epsg:4326' # Global lat-lon coordinate system\n",
    "    polar_to_latlon = pyproj.Transformer.from_crs(source_crs, target_crs, always_xy=True)\n",
    "    lat, lon = polar_to_latlon.transform(x,y)\n",
    "    return lon, lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otra opción de crear mapa con folium:\n",
    "import folium\n",
    "def generateBaseMap(loc, zoom=11, tiles='OpenStreetMap', crs='ESPG3857'):\n",
    "    return folium.Map(location=loc,\n",
    "                   #control_scale=True, \n",
    "                   zoom_start=zoom,\n",
    "                   #tiles=tiles)\n",
    "    )\n",
    "base_map = generateBaseMap([40.7127837, -74.0059413])\n",
    "\n",
    "\n",
    "marker = list(range(len(df2009.xcoord)))\n",
    "counter = 0\n",
    "tooltip = \"Click Here For More Info\"\n",
    "icon = folium.features.CustomIcon('https://cdn-icons-png.flaticon.com/128/7500/7500224.png', icon_size=(40, 40))\n",
    "\n",
    "for x,y in zip(df2009.xcoord, df2009.ycoord):\n",
    "    lon, lat = xy_to_latlon(x,y)\n",
    "    marker[counter] = folium.Marker(icon=icon,\n",
    "    #     #location=[40.7127837, -74.0059413],\n",
    "    location=[lon, lat],\n",
    "    #     #popup=\"<stong>Allianz Arena</stong>\",\n",
    "    #     #tooltip=tooltip\n",
    "    )\n",
    "    marker[counter].add_to(base_map)\n",
    "    #print(f\"latitud {lat} y longitud {lon}\")\n",
    "    if counter>5 : \n",
    "        break\n",
    "    counter += 1\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conteo de nulos\n",
    "#proc_df.info(verbose=True, show_counts=True,memory_usage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descripción de variables númericas:\n",
    "proc_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descripción de variables categóricas: \n",
    "proc_df.describe(include=\"O\").T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar df2010\n",
    "# df2 = pd.read_csv('2010_1perc.csv', index_col='Unnamed: 0')\n",
    "# df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('geopandas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cfc4558a56c74004f66639ccbe2b85f126442f2f38d8bdd913543c2f1bf5fd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
